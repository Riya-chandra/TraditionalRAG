{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e7d37229",
   "metadata": {},
   "source": [
    "### Data Ingestion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5fa5a8d",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da5b57a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='This is a sample document content. I m using to create RAG' metadata={'source': 'example', 'date': '2024'}\n"
     ]
    }
   ],
   "source": [
    "### Document data strcture\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "# Create a sample document\n",
    "doc = Document(\n",
    "\tpage_content=\"This is a sample document content. I m using to create RAG\",\n",
    "\tmetadata={\"source\": \"example\", \"date\": \"2024\"} #to create a good RAG do that i would be searhing parameter --> apply filters\n",
    ")\n",
    "\n",
    "print(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f20c1fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## creating a simple txt file\n",
    "\n",
    "import os\n",
    "os.makedirs(\"..data/text_files\",exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24e5e266",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(metadata={'source': '../data/text_files/pyhton_intro.txt'}, page_content='Python ek high-level, interpreted, aur general-purpose programming language hai — jo simple syntax aur human-readable code ke liye famous hai.\\nIska matlab: likhna aur samajhna dono easy hota hai.\\n\\nEasy to learn & read\\n✅ Cross-platform (Windows, Mac, Linux sab me chalta hai)\\n✅ Dynamic Typing (datatype likhne ki zarurat nahi)\\n✅ Huge library support\\n✅ Community support (sabse popular language hai)')]\n"
     ]
    }
   ],
   "source": [
    "###text loader\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "\n",
    "loader = TextLoader(\"../data/text_files/pyhton_intro.txt\", encoding=\"utf-8\")\n",
    "docs = loader.load()\n",
    "print(docs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a82f4bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': '..\\\\data\\\\text_files\\\\machine_learning.txt'}, page_content=''),\n",
       " Document(metadata={'source': '..\\\\data\\\\text_files\\\\pyhton_intro.txt'}, page_content='Python ek high-level, interpreted, aur general-purpose programming language hai — jo simple syntax aur human-readable code ke liye famous hai.\\nIska matlab: likhna aur samajhna dono easy hota hai.\\n\\nEasy to learn & read\\n✅ Cross-platform (Windows, Mac, Linux sab me chalta hai)\\n✅ Dynamic Typing (datatype likhne ki zarurat nahi)\\n✅ Huge library support\\n✅ Community support (sabse popular language hai)')]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## directory loader\n",
    "from langchain_community.document_loaders import DirectoryLoader\n",
    "\n",
    "dir_loader=DirectoryLoader(\n",
    "    \"../data/text_files\",\n",
    "    glob=\"**/*.txt\",  ## pattern to match files\n",
    "    loader_cls=TextLoader,  ## loader class to use\n",
    "    loader_kwargs={'encoding':'utf-8'},\n",
    "    show_progress=False\n",
    ")\n",
    "doc=dir_loader.load()\n",
    "doc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb049e1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'producer': 'Skia/PDF m140', 'creator': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/140.0.0.0 Safari/537.36', 'creationdate': '2025-10-09T09:55:27+00:00', 'source': '..\\\\data\\\\pdf\\\\1-04ee286a-ad42-4d86-ab8d-14d18b4fbd1a.pdf', 'file_path': '..\\\\data\\\\pdf\\\\1-04ee286a-ad42-4d86-ab8d-14d18b4fbd1a.pdf', 'total_pages': 1, 'format': 'PDF 1.4', 'title': 'Certificate', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T15:54:16+05:30', 'trapped': '', 'modDate': \"D:20251009155416+05'30'\", 'creationDate': \"D:20251009095527+00'00'\", 'page': 0}, page_content='Riya Chandra\\nIntroduction to Artificial Intelligence\\nThe certificate is awarded to\\nfor successfully completing the course\\non October 9, 2025\\nIssued on: Thursday, October 9, 2025\\nTo verify, scan the QR code at https://verify.onwingspan.com\\nArtificial Intelligence using Python\\n6'),\n",
       " Document(metadata={'producer': 'Canva', 'creator': 'Canva', 'creationdate': '2025-10-17T07:09:37+00:00', 'source': '..\\\\data\\\\pdf\\\\NikhilSoni_v8.pdf', 'file_path': '..\\\\data\\\\pdf\\\\NikhilSoni_v8.pdf', 'total_pages': 1, 'format': 'PDF 1.4', 'title': 'Copy of NikhilSoni_Resume@v8', 'author': 'NIKHIL SONI', 'subject': '', 'keywords': 'DAG1lIL49c8,BAFXLymrV-U,0', 'moddate': '2025-10-17T07:09:37+00:00', 'trapped': '', 'modDate': \"D:20251017070937+00'00'\", 'creationDate': \"D:20251017070937+00'00'\", 'page': 0}, page_content='NIKHIL SONI\\nCONTACT\\n+91 9263226570\\nnikhilprince973@gmail.com\\nKIIT, Bhubaneswar\\nhttps://www.linkedin.com/in/\\nnikhilsoni973/\\nhttps://green-bay-\\n02a2a5c1e.4.azurestaticapps.net\\nEDUCATION\\nGraduation- 2022-2026 (Pursuing)\\nKIIT (Kalinga Institute of Industrial\\nTechnology), Bhubaneswar\\nBachelor of Technology - CSE\\nCGPA  8.61\\n2021 - 12  Standard\\nth\\nDAV Public School, WALMI, Patna\\n91.6%\\n2019 - 10  Standard\\nth\\nDAV Public School, WALMI, Patna\\n94.3%\\nCERTIFICATION\\nSpecialization in Meta Back-\\nEnd Developer\\nCareer Essentials in Software\\nDevelopment - Microsoft &\\nLinkedIn\\nGit and GitHub - LinkedIn\\nBusiness for Good:\\nFundamentals of Corporate\\nResponsibility\\nLegacy JavaScript Algorithms\\nand Data Structures\\nMore on Linkedin\\nOther Profiles\\nMicrosoft Learn - nikhilsoni-3944\\nLeetCode - nikhil12soni \\nGeeksforGeeks - nikhilprsd53\\nHackerRank - nikhilprince973\\nPROFILE\\nA results-oriented final-year Computer Science student at KIIT University with a strong\\nfoundation in backend development, full-stack engineering, and AI-driven automation. Proficient\\nin the MERN stack, Python, and cloud platforms, with hands-on experience in building scalable,\\nefficient, and intelligent systems using Node.js, Next.js, and RESTful APIs. Eager to apply\\nproblem-solving skills and contribute to a dynamic software engineering team.\\nTECHNICAL SKILLS\\nLanguages : C/C++, Python, Java, HTML/CSS, JavaScript, SQL\\nFrameworks : React.js, Next.js Node.js, Express.js, MongoDB, FastAPI, tailwindCSS \\nPlatforms : Linux, Git, GitHub, Google Cloud Platform, AWS, Azure, Postman API \\nKey Areas : OOP, OS, DBMS, AI/ML\\nPROJECTS\\nCustomer Support Chatbot with CopilotKit and Azure OpenAI  - Link\\nEngineered an AI-powered customer support web application using Next.js 15, CopilotKit,\\nand Azure OpenAI to handle queries, generate support tickets, and manage file attachments\\nin real-time.\\nIntegrated MongoDB for persistent data storage and utilized Tailwind CSS for a responsive\\nuser interface, enabling intelligent, context-aware conversations.\\nTech Stack: Next.js, CopilotKit, Azure OpenAI, MongoDB\\nIntelligent File Organizer (AI Agent) - Link\\nDeveloped an autonomous file organizer that continuously monitors directories, classifying\\nfiles using Hugging Face Zero-Shot models for hands-free file management.\\nImplemented a resilient watcher system with rate limiting, custom folder mapping via YAML\\nconfigs, and features like dry-run mode and logging to ensure robust performance.\\nTech Stack: Python, Hugging Face Transformers, YAML\\nArchitected a production-grade web scraper using Python, BeautifulSoup, and Cloudscraper to\\nextract structured data and images from an e-commerce website.\\nAutomated category-wise scraping, image downloads, and CSV exports while integrating\\nrobust logging, error handling, and anti-bot protection for reliable data collection.\\nTech Stack: Python, BeautifulSoup, Requests, Cloudscraper\\nPC Jeweller Web Scraper - Link\\nCreated an AI-powered video summarization tool using Gemini 2.0 Flash, Node.js, and\\nReact.js to deliver concise insights from long videos.\\nIt generate accurate summaries, improving content accessibility.\\nTech Stack: Gemini 2.0 Flash, Node.js, React.js, Streamlit\\nAI Video Summarizer Gemini 2.0 Flash, Streamlit – Link\\nOpen Source Contributor: Actively contributed to AI and global tools on GitHub, including\\nprojects like VSCode.\\nYoCodex (in progress) – Building a community platform for sharing code snippets,\\ndeveloper tools, and resources to help techies collaborate and learn.\\nACHIEVEMENTS \\nPROBLEM SOLVING & COMPETITIVE PROGRAMMING\\nLeetCode Solved 200+ problems, strengthening skills in Data Structures and Algorithms.\\nGeeksforGeeks Completed 360+ problems covering DSA and system design concepts.\\nMicrosoft Learn Earned 31 badges demonstrating proficiency in Azure Cloud services, AI\\nagent development, and DevOps methodologies.'),\n",
       " Document(metadata={'producer': 'Skia/PDF m137 Google Docs Renderer', 'creator': '', 'creationdate': '', 'source': '..\\\\data\\\\pdf\\\\Self-Healing_Software_Systems_Lessons_from_Nature_[1].pdf', 'file_path': '..\\\\data\\\\pdf\\\\Self-Healing_Software_Systems_Lessons_from_Nature_[1].pdf', 'total_pages': 16, 'format': 'PDF 1.4', 'title': 'Self-Healing Software', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 0}, page_content='Self-Healing Software Systems: Lessons from Nature, Powered by AI \\nMohammad Baqar (baqar22@gmail.com), Rajat Khanda (rajat.mnnit@gmail.com), Saba Naqvi(sabanaqvi2003@gmail.com) \\nAbstract: As modern software systems grow in complexity and scale, their ability to \\nautonomously detect, diagnose, and recover from failures becomes increasingly vital. Drawing \\ninspiration from biological healing—where the human body detects damage, signals the brain, and \\nactivates targeted recovery—this paper explores the concept of self-healing software driven by \\nartificial intelligence. We propose a novel framework that mimics this biological model: system \\nobservability tools serve as sensory inputs, AI models function as the cognitive core for diagnosis \\nand repair, and healing agents apply targeted code and test modifications. By combining log \\nanalysis, static code inspection, and AI-driven generation of patches or test updates, our approach \\naims to reduce downtime, accelerate debugging, and enhance software resilience. We evaluate the \\neffectiveness of this model through case studies and simulations, comparing it against traditional \\nmanual debugging and recovery workflows. This work paves the way toward intelligent, adaptive, \\nand self-reliant software systems capable of continuous healing, akin to living organisms. \\n1. Introduction \\nModern \\nsoftware \\noperates \\nin \\ndynamic, \\nunpredictable \\nenvironments \\nwhere \\nerrors, \\nfailures, \\nand \\nregressions \\nare \\ninevitable. \\nProduction outages, flaky test failures, and \\nperformance bottlenecks demand significant \\nhuman effort for detection, diagnosis, and \\nrecovery. Despite advances in monitoring, \\nalerting, and automated testing, most software \\nsystems lack the ability to adaptively respond to \\ndisruptions without manual intervention, leading \\nto increased downtime and developer toil. \\nIn contrast, biological organisms like the human \\nbody exhibit remarkable self-healing capabilities. \\nThe body detects damage through sensory \\nsignals, processes them via the brain, and \\ntriggers coordinated healing responses—such \\nas immune activation or tissue regeneration—to \\nensure survival and adaptation. Inspired by this \\ndecentralized yet efficient process, we propose a \\nnew paradigm in software engineering: AI-driven \\nself-healing \\nsystems \\nthat \\nmimic biological \\nresilience. At the core of our approach is an \\nAI-powered decision-making unit, analogous to \\nthe brain, that interprets signals from logs, tests, \\nand runtime metrics to autonomously identify \\nissues and initiate repairs. \\nThis paper presents a conceptual and technical \\nframework for AI-driven self-healing in software \\napplications. Unlike conventional automated \\nrepair systems that rely on rigid rule-based \\nmechanisms or static scripts, our framework \\nemphasizes \\nadaptability \\nand \\ncontinuous \\nlearning. \\nBy \\nleveraging \\nmachine learning, \\nprogram synthesis, anomaly detection, and \\nautomated code refactoring, AI-driven agents \\ncan generate precise interventions—such as \\npatching code, rewriting failing tests, or rerouting \\nexecution flows—enabling resilient, intelligent \\nself-healing behaviors. We outline the following \\ncontributions: \\n●\\u200b\\nDefine a biologically inspired \\narchitecture for self-healing software \\n(Section 4). \\n●\\u200b\\nExplore key AI components for \\ndetection, diagnosis, and automated \\nrepair (Sections 4 and 5). \\n●\\u200b\\nPresent use cases in production \\nsystems and test automation (Section \\n5). \\n●\\u200b\\nEvaluate the benefits, limitations, and \\nfuture potential of autonomous software \\nhealing (Sections 5–8). \\nAs software systems trend toward greater \\nautonomy, self-healing capabilities will become \\nfoundational to their design, maintenance, and \\nevolution. This study lays the groundwork for \\nthat vision, integrating principles from biology \\nand artificial intelligence to engineer more \\nresilient, self-aware software ecosystems. \\n2. Biological Healing vs. Software \\nHealing: A Conceptual Analogy'),\n",
       " Document(metadata={'producer': 'Skia/PDF m137 Google Docs Renderer', 'creator': '', 'creationdate': '', 'source': '..\\\\data\\\\pdf\\\\Self-Healing_Software_Systems_Lessons_from_Nature_[1].pdf', 'file_path': '..\\\\data\\\\pdf\\\\Self-Healing_Software_Systems_Lessons_from_Nature_[1].pdf', 'total_pages': 16, 'format': 'PDF 1.4', 'title': 'Self-Healing Software', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 1}, page_content='2\\u200b\\nMohammad Baqar ,  Rajat Khanda , Saba Naqvi \\nThe human body possesses a remarkable \\ncapacity to detect damage, respond to threats, \\nand \\nrestore \\nits \\nfunctionality \\nthrough \\na \\nmulti-layered healing process. This intricate \\nsystem is orchestrated by the brain, sensory \\nnetworks, the immune system, and regenerative \\nmechanisms. Drawing parallels between this \\nbiological resilience and software systems offers \\na \\ncompelling \\nframework \\nfor \\ndesigning \\nself-healing architectures. \\n2.1. The Brain as the Central Controller → AI \\nOrchestration Engine \\nIn biological systems, the brain receives, \\nprocesses, and acts upon a constant stream of \\nsensory data to initiate appropriate responses. \\nSimilarly, in a self-healing software system, the \\ncore \\ndecision-making \\nentity \\nis \\nan \\nAI \\norchestration \\nengine—powered \\nby \\nlarge \\nlanguage models (LLMs), retrieval-augmented \\ngeneration (RAG), or reinforcement learning \\nframeworks [1][2]. This engine interprets inputs \\nfrom diverse system channels and triggers \\nhealing actions, such as regenerating tests, \\nrolling back faulty commits, or applying hotfixes. \\n2.2. \\nSignals \\nand \\nSensors \\n(Pain, \\nInflammation) → Logs, Monitoring, Tracing \\nBiological signals like pain, swelling, or fever act \\nas \\nindicators \\nof \\ndamage \\nor \\ninfection. \\nAnalogously, modern software systems emit a \\nvast array of signals through logs, performance \\nmetrics, trace events, and anomaly detection \\nsystems [3]. Tools like Prometheus, Datadog, or \\nOpenTelemetry function as the \"senses\" of the \\nsoftware, feeding real-time data into the central \\ncontroller for evaluation. \\n2.3. Immune System and Repair Agents → \\nHealing Scripts, AI Repair Models \\nJust as the immune system deploys white blood \\ncells to isolate and repair tissue damage, \\nself-healing systems can invoke automated \\nrepair agents—scripts or machine learning \\nmodels trained on historical failures and code \\nchange \\npatterns \\n[4]. \\nThese \\nagents \\ncan \\nauto-generate patches, update test cases, or \\neven suggest alternative logic paths based on \\nsemantic understanding of the failure. \\n2.4. \\nRegeneration \\nand \\nAdaptation \\n→ \\nRefactoring, Re-tests, Test Regeneration \\nSome biological organisms possess the ability to \\nregenerate lost tissues—such as skin or liver \\ncells. In software, this regenerative property \\nmanifests in the form of refactoring, test \\nregeneration, or resilient fallback code paths. \\nTools like GPT-based test writers or repair \\nframeworks like Prophet and Repairnator [5] can \\nlearn from context and rewrite or enhance faulty \\ncomponents, restoring system functionality with \\nminimal downtime. \\n2.5. Cellular Memory → Version History, Git, \\nObservability Stores \\nBiological cells retain memory of past infections \\n(as in adaptive immunity). Software achieves \\nsimilar long-term recall through version control \\nsystems like Git, combined with observability \\nplatforms that store historical logs, traces, and \\nerror patterns [6]. This memory allows the AI \\nengine to understand recurring issues, predict \\nregressions, and refine future healing strategies. \\n \\n3. State of the Art: Self-Healing \\nSystems in Software \\nHow have self-healing systems evolved to tackle \\nthe growing complexity of modern software? \\nOver \\nthe \\npast \\ntwo decades, self-healing \\nsoftware \\nhas \\nprogressed \\nfrom \\nreactive'),\n",
       " Document(metadata={'producer': 'Skia/PDF m137 Google Docs Renderer', 'creator': '', 'creationdate': '', 'source': '..\\\\data\\\\pdf\\\\Self-Healing_Software_Systems_Lessons_from_Nature_[1].pdf', 'file_path': '..\\\\data\\\\pdf\\\\Self-Healing_Software_Systems_Lessons_from_Nature_[1].pdf', 'total_pages': 16, 'format': 'PDF 1.4', 'title': 'Self-Healing Software', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 2}, page_content='Self-Healing Software Systems: Lessons from Nature, Powered by AI \\ninfrastructure fixes to proactive code repairs, \\nwith \\nAI \\nnow pushing the boundaries of \\nautonomy. This section reviews advancements \\nin \\nruntime \\nself-healing \\nmechanisms, \\nself-repairing code, test regeneration, and the \\ngrowing role of machine learning (ML) and \\nartificial \\nintelligence \\n(AI), \\nrevealing \\nboth \\nachievements and gaps in the field. \\n3.1. Runtime Self-Healing Systems \\nRuntime self-healing focuses on dynamically \\nadapting live systems to unexpected faults or \\nperformance \\ndegradation. \\nNetflix’s \\nChaos \\nMonkey [7] exemplifies this approach by \\nintentionally introducing failures in production \\nenvironments to test recovery mechanisms, \\nensuring \\nsystem \\nresilience. \\nSimilarly, \\nKubernetes, \\na \\nwidely \\nadopted \\ncontainer \\norchestration \\nplatform, \\nincorporates \\nnative \\nself-healing features like automatic pod restarts, \\nnode draining, and replica set rebalancing [8]. \\nFor instance, Kubernetes might restart a pod \\nafter detecting a crash via container health \\nchecks, ensuring availability but not addressing \\nthe underlying code flaw. These approaches rely \\non infrastructure-level redundancy and reactive \\nfailover mechanisms, offering robustness but \\nlimited introspection into the root causes of \\nsoftware-level issues. While runtime self-healing \\nensures system availability, it often overlooks \\ncode-level issues, prompting the development of \\nself-healing code techniques. \\n3.2. Self-Healing Code \\nSelf-healing code takes a deeper approach by \\nautomatically identifying and fixing the root \\ncauses of software bugs. Tools like GenProg [9] \\nand CodePhage [10] use genetic programming \\nand dynamic patch transplantation to generate \\nvalid patches for crashing programs. For \\nexample, GenProg mutates faulty code using a \\nfitness function based on passing test cases, \\niteratively evolving a patch—such as adjusting a \\nloop boundary to fix an off-by-one error. More \\nrecent advancements leverage large language \\nmodels (LLMs) like OpenAI’s Codex and GitHub \\nCopilot to suggest or synthesize repairs from \\ntest failures or natural language prompts [11]. \\nCodex might propose a null check to prevent a \\ncrash, drawing on patterns from vast code \\ncorpora. While these methods enable proactive \\nrepairs, their effectiveness varies, with GenProg \\nexcelling in syntactic fixes but struggling with \\ncomplex, multi-file bugs (Section 3.5). Beyond \\ncode repairs, self-healing extends to testing, \\nwhere \\nautomation \\naddresses \\nthe \\ngrowing \\nchallenge of flaky tests in CI/CD pipelines. \\n3.3. Self-Healing Tests \\nTest reliability is a critical concern in large CI/CD \\npipelines, where flaky tests and outdated \\nsnapshots often obstruct delivery. Self-healing \\ntesting frameworks aim to detect, isolate, and \\nrepair test failures autonomously. Techniques \\ninclude \\nflaky \\ntest \\ndetection by analyzing \\nhistorical \\nexecution \\npatterns, \\nsnapshot \\nregeneration in UI frameworks like Jest, and test \\ncase synthesis using symbolic execution or \\nfuzzing [12, 13]. For instance, tools might \\nidentify a test that fails only on certain OS \\nversions due to timing issues, then isolate and \\nrerun it under controlled conditions to confirm \\nflakiness. Some systems integrate with test \\norchestration platforms to auto-rerun failed \\ncases with controlled variance, while others use \\nAI to regenerate test inputs or expected outputs. \\nHowever, distinguishing between flaky failures \\nand genuine regressions remains a challenge, \\noften requiring manual oversight. As self-healing \\ntests improve CI/CD reliability, AI and ML are \\nnow transforming the field by enabling more \\nintelligent and unified healing approaches. \\n3.4. \\nRole \\nof \\nML \\nand \\nAI \\nin \\nCode \\nUnderstanding and Generation \\nAI’s growing influence in self-healing systems is \\ndriven \\nby foundation models like Codex, \\nCodeT5, and PolyCoder, trained on vast code \\ncorpora to infer intent, detect anti-patterns, and \\ngenerate repairs [14]. Reinforcement learning \\nand program synthesis have also been applied \\nto optimize test coverage and repair faulty \\nexecution traces [15]. For example, CodeT5 \\ncould unify Kubernetes runtime signals (Section \\n3'),\n",
       " Document(metadata={'producer': 'Skia/PDF m137 Google Docs Renderer', 'creator': '', 'creationdate': '', 'source': '..\\\\data\\\\pdf\\\\Self-Healing_Software_Systems_Lessons_from_Nature_[1].pdf', 'file_path': '..\\\\data\\\\pdf\\\\Self-Healing_Software_Systems_Lessons_from_Nature_[1].pdf', 'total_pages': 16, 'format': 'PDF 1.4', 'title': 'Self-Healing Software', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 3}, page_content='4\\u200b\\nMohammad Baqar ,  Rajat Khanda , Saba Naqvi \\n3.1) with GenProg’s code repairs (Section 3.2) \\nand flaky test detection (Section 3.3), creating a \\nmore integrated healing process by learning \\nfrom runtime signals, code, and test data \\nsimultaneously. However, these models require \\nfine-tuning \\nto avoid overfitting to generic \\npatterns and often struggle with domain-specific \\nlogic or dynamic runtime behavior, as they are \\nprone to hallucinations and lack transparency in \\ndecision-making [16]. Despite these challenges, \\nAI offers potential for end-to-end healing by \\nintegrating observability data (e.g., logs) with \\nrepair logic, though issues like domain-specific \\nreasoning remain unresolved (Section 3.5). \\n3.5. Shortcomings in Current Approaches \\nDespite \\nadvancements, current self-healing \\nsystems exhibit several critical limitations that \\nhinder their ability to provide comprehensive, \\nreliable solutions. These gaps, observed across \\nruntime, code, and test healing approaches, \\nhighlight the need for a unified, semantic-aware \\nframework like the one proposed in Section 4. \\nSiloed Healing: Most tools focus on a single \\naspect—runtime recovery (e.g., Kubernetes pod \\nrestarts), code repair (e.g., GenProg), or test \\nautomation (e.g., flaky test detection)—without \\nintegrating \\nthese \\nefforts \\ninto \\na \\ncohesive \\nfeedback loop. For example, Chaos Monkey \\n(Section 3.1) excels at runtime failure injection \\nbut cannot address code-level bugs, leaving \\ngaps in end-to-end healing.  \\nLack of Semantic Understanding: Machine \\nlearning-based code generators often fail to \\ngrasp business-specific constraints or complex \\narchitectural \\ndependencies. \\nFor \\ninstance, \\nGenProg’s genetic programming can patch a \\ncrashing loop with a syntactic fix, such as \\nadjusting an index, but struggles with bugs \\nrequiring multi-file reasoning—like a data race \\nacross \\nmicroservices—due \\nto \\nits lack of \\nawareness of broader program semantics. \\nSimilarly, LLMs like Codex may generate \\nplausible fixes, such as adding a null check to a \\nvariable, but without understanding  \\ndomain-specific \\nlogic, \\nthey \\nrisk \\nbreaking \\nconstraints, like financial calculations in a \\nbanking app where rounding errors could violate \\nregulations. \\nLimited \\nReal-Time \\nAdaptability: \\nMany \\nself-healing systems operate offline or require \\nsubstantial retraining and human oversight, \\nreducing \\ntheir \\neffectiveness \\nin \\ndynamic \\nenvironments. For example, tools relying on \\nhistorical test patterns (Section 3.3) may fail to \\nadapt \\nto \\nsudden \\nspikes \\nin \\nuser \\ntraffic, \\nnecessitating manual intervention to retrain \\nmodels, which delays recovery. \\nEvaluation \\nGaps: \\nThere \\nis \\na \\nlack \\nof \\nstandardized \\nbenchmarks \\nto \\nassess \\nthe \\nrobustness, safety, and long-term maintainability \\nof AI-generated repairs. While tools like Codex \\nachieve high success rates for isolated fixes \\n(Section 5.4), their patches may degrade over \\ntime—e.g., a fix passing tests today might fail \\nunder new workloads—highlighting the need for \\nlongitudinal evaluation metrics. \\nThese shortcomings underscore the necessity \\nfor \\na \\nholistic, \\ncontext-aware \\napproach. \\nGenProg’s \\nstruggles \\nwith \\narchitectural \\ndependencies \\nand \\nCodex’s \\nlimitations \\nin \\ndomain-specific \\nscenarios (e.g., introducing \\nsubtle errors in financial logic) reveal the critical \\nneed for semantic-aware healing. The proposed \\nAI-driven architecture (Section 4) aims to \\naddress these gaps by unifying observability, \\ndiagnosis, and repair in a feedback-driven loop, \\nenabling more robust and adaptive self-healing \\nsystems. \\nThe following table summarizes key approaches \\nto self-healing in software systems. \\n \\nApproach \\n \\nExample \\nTool \\nStrength \\n \\nLimitation \\n \\nRuntime \\nSelf-Healing \\nChaos \\nMonkey \\nRobust failure \\nrecovery \\nLimited root \\ncause insight \\nSelf-Healing \\nCode \\n \\nGenProg \\n \\nAutomated \\npatch \\ngeneration \\nStruggles with \\ncomplex bugs \\nSelf-Healing \\nTests \\nFlaky Test \\nTools \\nReduces CI/CD \\ndelays \\nFlaky vs. \\nregression \\nconfusion \\nAI/ML \\nIntegration \\nCodex \\nContextual \\ncode \\ngeneration \\nProne to \\nhallucinations'),\n",
       " Document(metadata={'producer': 'Skia/PDF m137 Google Docs Renderer', 'creator': '', 'creationdate': '', 'source': '..\\\\data\\\\pdf\\\\Self-Healing_Software_Systems_Lessons_from_Nature_[1].pdf', 'file_path': '..\\\\data\\\\pdf\\\\Self-Healing_Software_Systems_Lessons_from_Nature_[1].pdf', 'total_pages': 16, 'format': 'PDF 1.4', 'title': 'Self-Healing Software', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 4}, page_content='Self-Healing Software Systems: Lessons from Nature, Powered by AI \\nThe evolution of self-healing systems reflects a \\ntrajectory from infrastructure-level resilience \\n(e.g., Kubernetes) to code and test automation \\n(e.g., GenProg, flaky test detection), with AI now \\nenabling \\nmore \\nintelligent, \\ncontext-aware \\nsolutions. \\nHowever, \\ngaps \\nin \\nsemantic \\nunderstanding, \\nreal-time \\nadaptability, \\nand \\nevaluation standards persist, as detailed in \\nSection 3.5. These shortcomings highlight the \\nneed for a unified, AI-driven approach, which our \\nproposed framework (Section 4) aims to address \\nby integrating observability, diagnosis, and repair \\nin a cohesive loop.  \\n4. Proposed Framework: AI-Driven \\nSelf-Healing Architecture \\nInspired by the self-healing nature of biological \\nsystems, we propose a modular AI-driven \\narchitecture for autonomous software repair. \\nThis framework mirrors biological healing, where \\nthe brain interprets signals and initiates immune \\nresponses, reimagining this process within a \\nmodern software infrastructure. The pipeline \\nbegins with monitoring tools collecting signals \\n(e.g., error logs, performance metrics), which the \\ndiagnosis module analyzes using historical data, \\nbench marks and AI models to pinpoint faults. \\nThe healing agent then applies a fix, such as a \\ncode patch or test rewrite, which the verification \\nunit tests in a sandbox. Finally, the CI/CD loop \\ndeploys the fix or flags it for review based on \\npredefined \\npolicies, \\nensuring \\na seamless, \\nadaptive healing process. \\n4.1. Signal Collection \\nThe first step mirrors the nervous system \\nsensing pain or inflammation in the human body, \\ncollecting signals that indicate system stress, \\nfailure, or degradation. Monitoring tools like \\nDatadog, Grafana, New Relic, and Prometheus \\nprovide metrics, logs, and traces to identify \\nsymptoms \\nof \\nfailure \\n[7]. \\nFor \\nexample, \\nPrometheus might scrape a CPU spike of 90% \\non a critical server, while OpenTelemetry traces \\na slow API request to a database timeout, \\nfeeding both signals to the diagnosis module. \\nAdvanced systems can incorporate anomaly \\ndetection or tracing-based root cause analysis, \\nacting as neural sensors that channel data into \\nthe “central AI nervous system” for further \\ninterpretation. \\nThis \\ncomprehensive \\nsignal \\ncollection ensures the framework captures a \\nwide range of failure indicators, setting the stage \\nfor accurate diagnosis. \\n4.2. Diagnosis Module \\nOnce signals are collected, the diagnosis \\nmodule interprets them using AI models, akin to \\nthe brain analyzing sensory input to identify \\ninjury. Retrieval-Augmented Generation (RAG) \\nmodels pull historical context—such as past bug \\nreports—while Abstract Syntax Tree (AST) \\nparsers and Large Language Models (LLMs) like \\nCodex or Copilot analyze code structure and \\nsemantics [14]. For instance, an LLM might \\nexamine a stack trace alongside recent commits \\nvia RAG, identifying a null pointer exception \\ncaused by a new function missing input \\nvalidation. These models detect probable fault \\nlocations—like \\nlogic \\nbugs, \\nunhandled \\nexceptions, or outdated test assertions—that \\nconventional static analysis tools often miss. \\nUnlike traditional debugging tools, AI-enabled \\ndiagnosis learns patterns over time from a vast \\ncorpus of code repositories, improving its \\naccuracy with each iteration [15]. This module’s \\nability to combine historical data with real-time \\nsignals \\nensures \\nprecise \\nfault \\nlocalization, \\nenabling effective healing actions. \\n4.3. Healing Agent \\nThe healing agent, the core of the framework, \\ntriggers repair actions, mirroring the biological \\nimmune system’s role in neutralizing pathogens. \\nDepending \\non \\nconfidence \\nthresholds \\nand \\norganizational \\npolicies, \\nthe \\nagent \\ncan \\nrecommend or automatically apply fixes. For \\ncode defects, LLMs or genetic programming \\ntools like GenProg rewrite or mutate code based \\non learned bug-fix patterns [9]. For flaky tests, \\nsuch as a UI test failing due to a changed DOM, \\na test-oriented variant of CodeT5 regenerates \\nthe snapshot to match the updated element ID \\n[14]. Infrastructure issues, like misconfigurations \\nin deployment scripts, are corrected using \\n5'),\n",
       " Document(metadata={'producer': 'Skia/PDF m137 Google Docs Renderer', 'creator': '', 'creationdate': '', 'source': '..\\\\data\\\\pdf\\\\Self-Healing_Software_Systems_Lessons_from_Nature_[1].pdf', 'file_path': '..\\\\data\\\\pdf\\\\Self-Healing_Software_Systems_Lessons_from_Nature_[1].pdf', 'total_pages': 16, 'format': 'PDF 1.4', 'title': 'Self-Healing Software', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 5}, page_content='6\\u200b\\nMohammad Baqar ,  Rajat Khanda , Saba Naqvi \\ntemplate-based learning—e.g., adjusting a CI \\npipeline timeout. By addressing code, tests, and \\ninfrastructure, \\nthe \\nhealing \\nagent \\nensures \\ncomprehensive repairs, adapting its approach \\nbased on the nature of the fault and the system’s \\nrequirements, paving the way for rigorous \\nverification. \\n4.4. Verification Unit \\nHealing without verification risks introducing \\nregressions, so the verification unit acts as \\nregenerative tissue testing its integration before \\nbecoming permanent. Fixes are evaluated in a \\nsandboxed \\nenvironment \\nthrough \\nunit, \\nintegration, and end-to-end test suites. Mutation \\ntesting \\nensures \\nthe \\npatch \\ndoesn’t \\nmask \\nfaults—for example, verifying that a fix doesn’t \\npass tests by bypassing critical logic [17]. \\nCanary deployments in pre-production monitor \\nkey metrics like error rates for 10 minutes, \\nreverting if anomalies occur, such as a spike in \\n500 errors. If verification fails, the system rolls \\nback to the previous state, logging the issue for \\ndeveloper analysis to maintain stability. For \\nuntested edge cases, low-confidence fixes are \\nflagged for human review, balancing autonomy \\nwith safety. This rigorous validation ensures that \\nonly reliable fixes are deployed, protecting the \\nsystem from unintended consequences. \\n4.5. Feedback Loop Integration with CI/CD \\nThe framework integrates seamlessly with the \\norganization’s \\nCI/CD \\npipeline, \\ncreating \\na \\nself-sustaining \\nfeedback \\nloop \\nthat \\nmirrors \\nbiological \\nadaptation. \\nSignals \\nfrom \\nthe \\nmonitoring stack trigger healing actions, which \\nare verified and either rolled out automatically or \\nflagged for manual review based on thresholds \\nand risk profiles. Customization is supported via \\npolicy templates: startups might prioritize speed \\nby auto-applying all fixes, while enterprises \\nenforce strict review, flagging all code changes. \\nScalability \\nis \\nensured \\nthrough \\ndistributed \\nmonitoring agents and cloud-based AI inference, \\nhandling thousands of signals per second in \\nlarge systems [18]. Developers can configure \\npolicies—e.g., auto-patching known flaky tests \\nbut \\nflagging \\ncode \\nrefactoring \\nfor \\nreview—fostering trust and enabling graceful \\nadoption. \\nThis \\nfeedback \\nloop \\nensures \\ncontinuous improvement, adapting the system to \\nevolving conditions and enhancing its resilience \\nover time. \\n4.6 Potential Challenges \\nResource Overhead: Continuous monitoring \\nand \\nAI \\ninference \\nmay \\nstrain \\nresources, \\nparticularly in low-latency systems, requiring \\noptimization like edge-based processing. \\nModel Errors: LLMs may generate incorrect \\npatches (e.g., fixing a symptom but not the root \\ncause), necessitating robust verification. \\nIntegration \\nComplexity: \\nRetrofitting \\nthe \\nframework into legacy CI/CD pipelines may \\nrequire custom adapters for tools like Jenkins.'),\n",
       " Document(metadata={'producer': 'Skia/PDF m137 Google Docs Renderer', 'creator': '', 'creationdate': '', 'source': '..\\\\data\\\\pdf\\\\Self-Healing_Software_Systems_Lessons_from_Nature_[1].pdf', 'file_path': '..\\\\data\\\\pdf\\\\Self-Healing_Software_Systems_Lessons_from_Nature_[1].pdf', 'total_pages': 16, 'format': 'PDF 1.4', 'title': 'Self-Healing Software', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 6}, page_content=\"Self-Healing Software Systems: Lessons from Nature, Powered by AI \\nAI-driven \\nself-healing \\nsystems \\noffer \\na \\ntransformative vision for software maintenance, \\nautomating \\nthe \\ndetection, \\ndiagnosis, \\nand \\nresolution of issues in real-time. By leveraging \\nadvanced techniques like machine learning, \\ncode analysis, and predictive modeling, these \\nsystems—such as the framework proposed in \\nSection 4—can identify anomalies, bugs, and \\nperformance bottlenecks, achieving recovery \\ntimes up to 55–70% faster than manual fixes, as \\ndemonstrated in the prototype (Section 5.4). \\nThis automation reduces the need for human \\nintervention, freeing developers to focus on \\nstrategic innovation rather than repetitive error \\nfixing. The biological analogy introduced in \\nSection 2 provides an intuitive lens: just as the \\nhuman body uses neural signals to guide \\nimmune responses and repair damaged cells, \\nself-healing software relies on AI to monitor logs, \\ntelemetry, and error reports, directing the healing \\nprocess through modules like Signal Collection \\nand Healing Agent (Section 4). \\nThis analogy’s strength lies in its clarity, making \\nthe concept accessible to both technical and \\nnon-technical stakeholders. Like the body’s \\nability to adapt and regenerate post-injury, \\nsoftware systems can self-correct and recover \\nfrom failures, as seen in the prototype’s 85–90% \\nsuccess rate for syntactic bugs (Section 5.4). \\nContinuous learning, enabled by feedback loops \\n(Section \\n4.5), \\nfosters \\nresilience, \\nallowing \\nsystems to evolve with changing conditions. \\nLooking \\nahead, \\nself-reliant software could \\nmanage \\nits \\nentire \\nlifecycle \\nautonomously, \\nminimizing downtime and boosting efficiency. As \\nAI models advance—addressing challenges like \\nsemantic understanding and scalability (Section \\n7)—the vision of fully autonomous, adaptable \\nsoftware \\nsystems \\nbecomes \\nincreasingly \\nachievable, \\nrevolutionizing \\nsoftware \\ndevelopment and support for a more reliable \\ndigital future. \\n5. Implementation & Prototype \\nTo \\nvalidate \\nthe proposed framework, we \\ndeveloped a proof-of-concept prototype that \\nleverages AI-driven healing mechanisms within \\na CI/CD pipeline. The prototype combines static \\ncode analysis, large language models (LLMs), \\nand observability data to detect, diagnose, and \\nrepair common issues in code and test suites. \\nPrototype Components: \\n5.1. Fault Detection using LLM + Static \\nAnalysis:\\u200b\\n We employ abstract syntax tree (AST) traversal \\nin combination with large language models \\n(LLMs) such as OpenAI Codex to analyze code \\nstructure and identify anomalies or anti-patterns. \\nCodex is prompted with a template: ‘Given error \\nlog [stack trace] and code [snippet], suggest a \\nfix.’ AST traversal uses a TypeScript parser to \\nidentify unhandled promises, reducing false \\npositives. By parsing the code into its syntactic \\ncomponents, \\nAST \\ntraversal \\nprovides \\na \\nstructured foundation for understanding the \\nprogram's logic. This structured representation is \\nthen paired with LLMs, which are prompted \\nusing relevant context—including code snippets, \\nrecent test failures, and commit history—to infer \\nprobable root causes and suggest candidate \\npatches. This hybrid approach enhances both \\nthe precision of fault localization and the quality \\nof automated code repair. \\n5.2. Healing Workflow Integration:\\u200b\\nThe system is seamlessly integrated into both \\nGitHub Actions workflows and Jenkins pipelines \\nto enable automated response to build failures \\nor test crashes. When such an event is \\ndetected, relevant logs and code diffs are \\nimmediately collected to provide context. Logs \\nare parsed using regex to extract error codes, \\nwhich are fed to Codex alongside the last 10 \\ncommits from Git. Patches are applied via a \\nGitHub Actions step that creates a temporary \\nbranch. This information is then passed to a \\nlarge language model (LLM), which generates \\npatch suggestions and rewrites test cases based \\non \\nthe \\nobserved \\nissue. \\nThe \\ncontinuous \\nintegration (CI) system subsequently applies the \\nproposed fix in a temporary branch and \\nexecutes a full suite of validation tests to assess \\nthe effectiveness of the correction, ensuring \\n7\"),\n",
       " Document(metadata={'producer': 'Skia/PDF m137 Google Docs Renderer', 'creator': '', 'creationdate': '', 'source': '..\\\\data\\\\pdf\\\\Self-Healing_Software_Systems_Lessons_from_Nature_[1].pdf', 'file_path': '..\\\\data\\\\pdf\\\\Self-Healing_Software_Systems_Lessons_from_Nature_[1].pdf', 'total_pages': 16, 'format': 'PDF 1.4', 'title': 'Self-Healing Software', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 7}, page_content=\"8\\u200b\\nMohammad Baqar ,  Rajat Khanda , Saba Naqvi \\nstability before any changes are merged into the \\nmain codebase. \\n5.3. Verification & Feedback Loop:\\u200b\\n A sandboxed test suite is employed to validate \\nthe auto-generated fix in a controlled and \\nisolated environment. This process includes \\nre-running unit and integration tests to confirm \\nthat the fix resolves the issue without introducing \\nnew problems. If a patch fails verification (e.g., \\nnew test failures), the system reverts the \\ntemporary branch and retries with an alternative \\nfix up to three times. Persistent failures trigger a \\ndeveloper alert with diagnostic logs, ensuring no \\nsilent errors disrupt the pipeline. \\nAdditionally, mutation testing is conducted to \\nensure regression resistance and robustness of \\nthe updated code. Mutation testing uses PIT to \\ninject faults, ensuring the patch doesn’t bypass \\ncritical logic. If the system is operating in a \\nsemi-autonomous mode, an optional human \\nreview is triggered via pull request comments, \\nallowing developers to inspect and approve the \\nproposed changes before final integration. This \\nlayered \\nvalidation \\napproach \\nbalances \\nautomation with oversight to maintain software \\nquality and trust. \\n5.4 Simulation Environment: \\nTo assess effectiveness, we ran experiments \\ninvolving: \\nSynthetic Bug Injection: To evaluate the \\neffectiveness \\nand \\nresponsiveness \\nof \\nthe \\nself-healing \\nprototype, \\nwe \\nsystematically \\nintroduced synthetic bugs into JavaScript and \\nTypeScript codebases. These injected bugs \\nmimicked \\nreal-world \\nscenarios \\ncommonly \\nencountered in production environments, such \\nas off-by-one errors in loops or array indexing, \\nmissing null or undefined checks, improper type \\nhandling, \\nand \\nmisconfigured \\nasynchronous \\nlogic. In parallel, we also induced common \\ntest-related failures like outdated snapshot tests, \\nbrittle assertions, and unhandled async test \\ncases. This controlled injection of faults provided \\na reliable basis for assessing how well the \\nsystem could detect, diagnose, and repair \\ndiverse \\nclasses \\nof \\nerrors \\nunder \\nrealistic \\nconditions. \\nAutonomous Healing Trigger: Once a build \\nfailure or test crash was detected through the \\nCI/CD \\npipeline, \\nthe \\nsystem's autonomous \\nhealing logic was automatically activated. This \\nincluded capturing contextual information such \\nas error logs, stack traces, diffs from recent \\ncommits, and test outputs. The large language \\nmodel (LLM), integrated into the workflow, then \\nanalyzed this context and generated candidate \\npatches \\nor \\ntest \\ncase \\nrewrites. \\nThese \\nsuggestions were automatically applied in a \\ntemporary Git branch, triggering a fresh CI run. \\nThe healing process was fully automated, \\nenabling the prototype to attempt immediate \\nrecovery \\nwithout \\nhuman \\nintervention. \\nIn \\nsemi-autonomous mode, the system would also \\nnotify developers with pull request comments \\nsummarizing the patch and offering optional \\nmanual approval. \\nRecovery Time vs. Manual Fixing: To measure \\nthe \\npractical \\nimpact \\nof \\nthe \\nsystem, we \\nbenchmarked \\nthe \\nrecovery \\ntime \\nof \\nthe \\nself-healing \\nmechanism \\nagainst \\ntraditional \\ndeveloper-led debugging and patching. The \\nmetric focused on the duration from the initial \\nfailure detection to a passing build. Preliminary \\nresults indicated that for a wide range of \\ncommon \\nfault \\nclasses—particularly \\nthose \\ninvolving syntax issues, small logic bugs, and \\nflaky tests—the system achieved resolution \\ntimes 55–70% faster than manual fixes. These \\nimprovements \\nwere \\nrealized \\nwithout \\ncompromising code quality, as validated by \\npost-repair test suites and mutation testing. This \\nperformance \\nhighlights \\nthe \\npotential \\nof \\nAI-assisted healing to significantly accelerate the \\ndevelopment lifecycle, reduce mean time to \\nrepair (MTTR), and alleviate developer toil in \\ncontinuous integration workflows. \\nObservations: \\nDuring evaluation, the system showed high \\neffectiveness \\nfor \\nsyntactic \\nor \\nlocalized \\nbugs—like \\noff-by-one \\nerrors, \\nmissing\"),\n",
       " Document(metadata={'producer': 'Skia/PDF m137 Google Docs Renderer', 'creator': '', 'creationdate': '', 'source': '..\\\\data\\\\pdf\\\\Self-Healing_Software_Systems_Lessons_from_Nature_[1].pdf', 'file_path': '..\\\\data\\\\pdf\\\\Self-Healing_Software_Systems_Lessons_from_Nature_[1].pdf', 'total_pages': 16, 'format': 'PDF 1.4', 'title': 'Self-Healing Software', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 8}, page_content='Self-Healing Software Systems: Lessons from Nature, Powered by AI \\nsemicolons, or broken test assertions—which \\nare typically confined to small code blocks and \\nrequire minimal context. These were ideal for \\nautomated fixes via static analysis and LLMs. \\nHowever, performance declined for complex \\nsemantic issues involving multi-file reasoning, \\nbusiness logic, or asynchronous flows, where \\nbroader \\ncontextual \\nunderstanding \\nwas \\ncrucial—an area where current LLMs still \\nstruggle without fine-tuning or human feedback. \\nNotably, combining AST traversal with LLM \\nreasoning reduced hallucinations and improved \\naccuracy, as the AST provided structured code \\ncontext that constrained the model’s suggestions \\nto valid outputs. \\nTo test generalizability, we applied the prototype \\nto a Python-based microservice and a react and \\nnode js based micro-app, achieving 50–70% \\nsuccess rates for common bugs like memory \\nleaks and API timeouts, though domain-specific \\nlogic posed challenges. \\nIn semi-autonomous mode, where developers \\nreviewed AI-generated patches, over 60% were \\naccepted \\nwith \\nlittle \\nto \\nno \\nmodification—highlighting strong alignment with \\ndeveloper expectations and positioning the tool \\nas an effective co-pilot rather than a full \\nreplacement. \\nThe prototype’s performance varied by bug type \\nand complexity. Syntactic bugs, like missing \\nsemicolons, \\nwere \\nresolved \\nreliably, \\nwhile \\nsemantic issues, like incorrect business logic, \\nrequired broader context. The table below \\nsummarizes key metrics, highlighting strengths \\nand areas for improvement. \\nObservation \\nArea \\nInsight \\nQuantitative \\nMetric / Note \\nBug Type - \\nSyntactic / \\nLocalized \\nHigh healing success \\nrate \\n85–90% patch \\nsuccess \\nBug Type - \\nSemantic / \\nComplex \\nLower healing \\neffectiveness due to \\nbroader context \\n ~40–50% \\nsuccess \\nrequirements \\nHybrid AST + \\nLLM vs. \\nLLM-Only \\nReduced \\nhallucinations and \\nimproved precision in \\npatch generation \\n 35–50% fewer \\ninvalid patches \\ncompared to \\nLLM-only \\napproach \\nDeveloper \\nPatch \\nAcceptance \\nHigh acceptance rate \\nin semi-autonomous \\nmode \\n 60–65% patches \\naccepted with \\nminimal/no edits \\nTime to \\nResolution \\nFaster bug recovery \\nfor common faults vs. \\nmanual intervention \\nUp to 70% faster \\nrecovery \\n5.5 Scalability Considerations \\nLarge Codebases: “For a 1M-line codebase, \\nthe system processes logs in batches to avoid \\nmemory bottlenecks, taking ~30 seconds per \\nbug.” \\nCI/CD Load: “High-frequency pipelines are \\nsupported via parallelized AI inference, handling \\n100 builds/hour with a 16-core server.” \\nResource Limits: “In edge environments, \\nlightweight models (e.g., distilled CodeT5) \\nreduce latency to 100ms per diagnosis.” \\n6. Evaluation \\nTo measure the effectiveness of the proposed \\nself-healing framework, the following metrics can \\nbe used: \\n6.1 Bug Detection Accuracy: \\nMeasured as the F1-score (harmonic mean of \\nprecision and recall) of detected bugs compared \\nto a labeled dataset of known faults. The ability \\nof the AI-driven system to identify faults in the \\ncode or tests. This metric evaluates how well the \\nAI models (such as LLMs or Codex) can detect \\nbugs, both common and edge cases, compared \\nto human or traditional static analysis tools. As \\nshown in Section 5.4, the prototype achieved \\n85–90% accuracy for syntactic bugs using AST \\nand LLM analysis, outperforming static tools like \\nESLint. Prior research has shown that neural \\nmodels can outperform traditional tools in \\ndetecting certain bug classes by learning \\ncontextual patterns beyond syntactic cues [19]. \\n9'),\n",
       " Document(metadata={'producer': 'Skia/PDF m137 Google Docs Renderer', 'creator': '', 'creationdate': '', 'source': '..\\\\data\\\\pdf\\\\Self-Healing_Software_Systems_Lessons_from_Nature_[1].pdf', 'file_path': '..\\\\data\\\\pdf\\\\Self-Healing_Software_Systems_Lessons_from_Nature_[1].pdf', 'total_pages': 16, 'format': 'PDF 1.4', 'title': 'Self-Healing Software', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 9}, page_content=\"10\\u200b\\nMohammad Baqar ,  Rajat Khanda , Saba Naqvi \\n6.2 Repair Success Rate: \\nCalculated as the percentage of AI-generated \\npatches that pass all unit and integration tests \\nwithout introducing regressions. The success \\nrate of automated repairs made by the AI \\nsystem. This metric measures how often the AI \\nmodel can apply fixes (such as code patches or \\ntest rewrites) that are both correct and effective, \\nwithout \\nintroducing \\nadditional \\nerrors \\nor \\nregressions. This follows work in automated \\nprogram repair, where test-suite-based repair \\nsystems \\nlike \\nRecoder \\nor \\nAlphaRepair \\ndemonstrated success rates ranging from 45% \\nto over 70% in benchmark suites, depending on \\nfault type and test coverage [20]. \\n6.3 Developer Effort Saved: \\nQuantified by comparing developer hours spent \\ndebugging with and without the system, using \\ntime-tracking tools. The reduction in manual \\nintervention required by developers when using \\nthe self-healing system. This metric helps to \\nquantify the amount of work saved by the \\nautomation, \\nincluding \\ntime spent on bug \\nidentification, debugging, and testing. \\n6.4 Time to Recovery: \\nDefined as the duration from failure detection to \\na passing CI build, averaged across bug types. \\nThe time taken for the system to recover from \\nfailures or bugs, comparing the time taken for \\nAI-based \\nhealing \\nvs. \\nmanual intervention. \\nShorter recovery times indicate more efficient \\nhealing processes, directly improving system \\nuptime. The prototype reduced recovery time by \\n55–70% for common faults (Section 5.4), \\n highlighting the framework’s efficiency. \\n6.5 Baseline Comparison: \\nConducted using A/B testing, where the AI \\nsystem’s performance is compared to static tools \\nlike ESLint or human fixes on identical bugs. \\nComparing the self-healing system against \\nhuman fixes or static tools. This baseline allows \\nfor an objective comparison of the AI-driven \\napproach's performance in real-world scenarios \\nand offers insights into the areas where \\nautomation \\nexcels \\nor \\nrequires \\nfurther \\nimprovement. Beyond effectiveness, we assess \\ncomputational overhead (e.g., seconds per \\npatch) \\nand \\npatch \\nmaintainability \\n(e.g., \\npercentage of patches requiring rework within 30 \\ndays) to ensure practical deployment. The \\nsystem is compared to static analysis tools like \\nESLint for syntactic bugs and SapFix for code \\nrepairs, as well as manual debugging by \\ndevelopers \\nwith \\n5+ years of experience. \\nScenarios include flaky test resolution in CI \\npipelines and runtime crashes in Node.js \\napplications. A similar comparative methodology \\nwas employed in [21], where the efficacy and \\npracticality of automated repair tools were \\nevaluated against developer-written patches and \\nstatic analysis systems. \\nFollowing Table summarizes the metrics with \\nexample values from the prototype, illustrating \\nthe framework’s potential impact. \\nMetric \\nDescription \\nExample \\nValue \\nBug Detection \\nAccuracy \\nF1-score of \\ndetected bugs \\n85% for syntactic \\nbugs \\nRepair Success \\nRate \\n% of patches \\npassing tests \\n80% overall \\nDeveloper Effort \\nSaved \\n \\nHours saved vs. \\nmanual debugging \\n10 hours/week \\n \\nTime to Recovery \\n \\nTime from failure to \\npassing build \\n15 minutes vs. \\n45 (manual) \\nBaseline \\nComparison \\n \\nAI vs. static tools \\n(success rate) \\n20% higher than \\nESLint \\n\\u200b6.6 Challenges in Evaluation \\nBug Detection Accuracy: False positives may \\ninflate \\naccuracy \\nif \\nedge \\ncases \\nare \\nunderrepresented in test datasets.\"),\n",
       " Document(metadata={'producer': 'Skia/PDF m137 Google Docs Renderer', 'creator': '', 'creationdate': '', 'source': '..\\\\data\\\\pdf\\\\Self-Healing_Software_Systems_Lessons_from_Nature_[1].pdf', 'file_path': '..\\\\data\\\\pdf\\\\Self-Healing_Software_Systems_Lessons_from_Nature_[1].pdf', 'total_pages': 16, 'format': 'PDF 1.4', 'title': 'Self-Healing Software', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 10}, page_content='Self-Healing Software Systems: Lessons from Nature, Powered by AI \\nDeveloper Effort Saved: Subjective estimates \\nof effort vary by developer experience, requiring \\nstandardized tasks for comparison. \\nTime to Recovery: Complex bugs may skew \\naverages, necessitating separate metrics for \\nsyntactic vs. semantic issues. \\nThese metrics are essential for evaluating the \\nfeasibility and efficiency of self-healing systems \\nin \\nreal-world \\napplications \\nand \\nprovide \\nbenchmarks \\nfor \\nfuture \\nenhancements \\nin \\nAI-driven software development. \\n7. Challenges & Limitations \\n7.1 False Positives or Wrong Patches \\nA critical challenge in AI-driven self-healing \\nsystems is the risk of false positives or incorrect \\npatches, which can disrupt system stability. \\nFalse positives occur when the system identifies \\na non-existent issue, while wrong patches fail to \\naddress the root cause or introduce new bugs. \\nFor example, the Diagnosis Module (Section \\n4.2) might misinterpret a temporary spike in \\nCPU \\nusage—captured \\nvia \\nPrometheus \\nmetrics—as a performance bug, triggering an \\nunnecessary optimization patch that increases \\nlatency by 10%, as observed in the prototype’s \\n10% false positive rate for complex bugs \\n(Section 5.4). This issue stems from the \\nsystem’s limited ability to fully interpret the \\ncontext \\nof \\nthe \\napplication, \\nincluding \\nits \\ndependencies, \\nenvironment, \\nand \\nruntime \\nbehavior. In one prototype test, the AI flagged a \\ndatabase query as the cause of a timeout based \\non historical patterns, but the true issue was a \\nnetwork latency spike, leading to an ineffective \\nfix. To address this, we propose using ensemble \\nlearning \\nto \\ncombine \\nLLMs with anomaly \\ndetection models, cross-validating bug detection \\nto reduce false positives. Additionally, integrating \\nfeedback loops—where developer rejections of \\nincorrect \\npatches \\nfine-tune \\nCodex’s \\nweights—can enable the system to learn from \\nmistakes. For critical patches, manual oversight \\nvia pull request reviews (as implemented in the \\nprototype’s semi-autonomous mode, Section \\n5.3) ensures reliability, minimizing disruptions \\nwhile improving the accuracy of AI-driven \\nhealing over time. \\n7.2 Over-Reliance on AI Hallucinations \\nWhat happens when an AI generates a harmful \\nfix? AI hallucinations—where models produce \\nplausible \\nbut \\nincorrect \\noutputs—pose \\na \\nsignificant risk in self-healing systems. In code \\nrepair, the Healing Agent (Section 4.3) might \\ngenerate a seemingly valid but flawed patch, \\nsuch as adding an incorrect null check to a \\nTypeScript async function, breaking the API flow \\nin 5% of the prototype’s test cases (Section 5.4). \\nThis issue arises because LLMs, like Codex, \\nrely \\non \\nhistorical \\npatterns \\nwithout \\nfully \\nunderstanding the underlying issue or broader \\ncodebase, potentially leading to catastrophic \\nfailures \\nin \\nproduction. \\nFor \\ninstance, \\na \\nhallucinated patch might bypass a security \\ncheck, exposing vulnerabilities. The core risk \\nlies in the model’s inability to independently \\nverify \\nits \\nsuggestions \\nagainst \\nreal-world \\noutcomes. To mitigate this, we propose using \\nconstrained decoding to limit LLM outputs to \\nsyntactically valid patches, ensuring they align \\nwith the codebase’s structure. Additionally, \\nintegrating mutation testing (Section 4.4) into the \\nverification pipeline can catch harmful fixes by \\nsimulating fault scenarios—e.g., ensuring a \\npatch doesn’t mask a deeper logic error. Limiting \\nautonomy in high-stakes scenarios, such as \\nfinancial applications, and using explainability \\ntools like SHAP to provide developers with \\ninsights into AI decisions further ensures \\ntrustworthiness. \\nThese \\nlayered \\nchecks, \\ncombined \\nwith the prototype’s CI testing \\n(Section 5.2), help balance automation with \\nreliability, preventing harmful hallucinations from \\nimpacting system integrity. This challenge is \\nwidely acknowledged in recent studies on LLMs \\nin software engineering, such as [22], which \\nhighlights risks of misleading or faulty code \\ncompletions \\nproduced \\nby \\nstate-of-the-art \\nmodels. \\n11'),\n",
       " Document(metadata={'producer': 'Skia/PDF m137 Google Docs Renderer', 'creator': '', 'creationdate': '', 'source': '..\\\\data\\\\pdf\\\\Self-Healing_Software_Systems_Lessons_from_Nature_[1].pdf', 'file_path': '..\\\\data\\\\pdf\\\\Self-Healing_Software_Systems_Lessons_from_Nature_[1].pdf', 'total_pages': 16, 'format': 'PDF 1.4', 'title': 'Self-Healing Software', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 11}, page_content='12\\u200b\\nMohammad Baqar ,  Rajat Khanda , Saba Naqvi \\n7.3 Code Context Sensitivity and Intent \\nPreservation \\nPreserving the developer’s intent while healing \\ncode is a fundamental challenge for AI-driven \\nself-healing systems. Code embodies not just \\ninstructions but also the logic and goals of its \\ncreator, requiring the AI to understand both its \\ntechnical structure and the broader context in \\nwhich it operates. Without this understanding, \\nfixes may be syntactically correct but functionally \\ndisastrous. For instance, in the prototype \\n(Section 5.4), the Healing Agent (Section 4.3) \\nattempted to fix a syntax error in a payment \\nprocessing \\nfunction \\nby \\nadjusting \\na \\nloop \\nboundary, but this broke the transaction logic, \\ncontributing to the 40–50% success rate for \\nsemantic bugs. The AI lacked insight into the \\nfunction’s role in ensuring financial accuracy, \\ndisrupting the application’s workflow. To address \\nthis, the system must go beyond syntax analysis \\nand incorporate semantic understanding of the \\ncode’s \\nlogic, \\ndependencies, \\nand intended \\noutcomes. We propose using program slicing to \\nisolate \\nrelevant \\ncode \\ndependencies—e.g., \\ntracing \\nvariables \\naffecting \\nthe \\npayment \\nfunction—and prompting LLMs with summarized \\nfunction comments extracted via NLP tools like \\nBERT to capture intent. Additionally, integrating \\ndeveloper input through annotations or feedback \\nduring the healing process (as seen in the \\nprototype’s semi-autonomous mode, Section \\n5.3) ensures patches align with the code’s goals, \\nreducing unintended side effects and improving \\nthe system’s ability to handle context-sensitive \\nrepairs. Similar challenges and techniques for \\ncapturing intent in automated program repair are \\ndiscussed in [23], which emphasizes the role of \\nintent-aware \\nmodels \\nin \\nimproving \\nrepair \\naccuracy. \\n7.4 Ethical and Accountability Concerns \\nIn mission-critical systems like healthcare, can \\nfully autonomous healing be trusted? The \\ndeployment of AI-driven self-healing systems \\nraises \\nprofound \\nethical \\nand accountability \\nconcerns, particularly regarding automation’s \\nunintended consequences. When the Healing \\nAgent (Section 4.3) autonomously applies a \\npatch, accountability for failures—such as a \\nsecurity \\nvulnerability \\nexposing \\npatient \\ndata—becomes unclear: is the developer, the \\norganization, or the AI responsible? This \\nambiguity is critical in domains like healthcare, \\nfinance, or transportation, where errors can have \\nsevere consequences. In the prototype’s tests \\n(Section 5.4), 5% of patches introduced subtle \\nregressions, underscoring the risk in high-stakes \\nscenarios. Ethical concerns also extend to \\ntransparency and fairness, as AI models may \\nperpetuate biases from flawed training data, \\npotentially prioritizing certain bug types over \\nothers. To mitigate these risks, we propose \\nadopting OpenTelemetry for detailed change \\nlogging, capturing every AI action for audit trails. \\nExplainability tools like SHAP can provide \\ndevelopers with insights into AI decisions—e.g., \\nwhy \\na \\npatch \\nwas \\napplied—enhancing \\ntransparency. The prototype’s semi-autonomous \\nmode (Section 5.3) already flags high-risk \\npatches \\nfor \\nhuman \\nreview, \\nand \\nthis \\nhuman-in-the-loop \\napproach \\nmust \\nremain \\nintegral, especially in sensitive applications. \\nFinally, ensuring fairness requires curating \\ndiverse training data and using fairness-aware \\nalgorithms to prevent biased healing decisions, \\nfostering trust in AI-driven systems. Ethical \\nconsiderations and governance strategies for AI \\nin critical infrastructure are further explored in \\n[24], \\nhighlighting \\nthe \\nimportance \\nof \\naccountability, auditability, and human oversight. \\n7.5 Scalability and Integration Challenges \\nThe framework’s reliance on real-time AI \\ninference may incur high computational costs, \\nparticularly for large codebases with frequent \\nCI/CD runs. For example, processing 1,000 \\nsignals/second could require a dedicated GPU \\ncluster, challenging resource-constrained teams. \\nAdditionally, integrating with legacy systems \\nlacking \\nmodern \\nobservability \\ntools \\n(e.g., \\nPrometheus) may require custom adapters, \\nincreasing setup complexity. Solutions include \\nlightweight models (e.g., distilled CodeT5) and \\nmodular APIs for legacy compatibility.'),\n",
       " Document(metadata={'producer': 'Skia/PDF m137 Google Docs Renderer', 'creator': '', 'creationdate': '', 'source': '..\\\\data\\\\pdf\\\\Self-Healing_Software_Systems_Lessons_from_Nature_[1].pdf', 'file_path': '..\\\\data\\\\pdf\\\\Self-Healing_Software_Systems_Lessons_from_Nature_[1].pdf', 'total_pages': 16, 'format': 'PDF 1.4', 'title': 'Self-Healing Software', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 12}, page_content='Self-Healing Software Systems: Lessons from Nature, Powered by AI \\nFollowing Table summarizes the challenges and \\nproposed mitigations, highlighting the path to a \\nrobust self-healing system. \\nChallenge \\nDescription \\nMitigation \\nFalse Positives/ \\nWrong Patches \\nMisdetected \\nbugs or harmful \\nfixes \\nEnsemble learning, \\ndeveloper feedback \\nloops \\nAI Hallucinations \\nIncorrect, \\nplausible patches \\nConstrained decoding, \\nmutation testing \\nCode Context \\nSensitivity \\n \\nFixes breaking \\nintent or logic \\nProgram slicing, \\nNLP-based \\nsummarization \\nEthical/ \\nAccountability \\n \\nUnclear \\nresponsibility for \\nfailures \\nOpenTelemetry logs, \\nSHAP explainability \\nScalability/ \\nIntegration \\n \\nHigh costs, \\nlegacy system \\nissues \\nLightweight models, \\nmodular APIs \\n \\n8. Future Directions \\nFuture work may explore addressing current \\nlimitations such as context sensitivity (Section \\n7.3) and accountability (Section 7.4). Improving \\nthese aspects could enhance the robustness, \\nscalability, and trustworthiness of AI-driven \\nself-healing systems, supporting their adoption \\nin real-world scenarios. \\n8.1 Integration with Observability Platforms \\nImagine a latency spike undetected by logs \\nalone—observability platforms can bridge this \\ngap. Integrating self-healing systems with tools \\nlike \\nDatadog, \\nGrafana, \\nand \\nPrometheus \\nsignificantly enhances their effectiveness by \\nproviding a comprehensive view of system \\nhealth. The Signal Collection module (Section \\n4.1), which currently relies on basic logs, could \\nincorporate Grafana dashboards to correlate a \\n500ms latency spike with a specific API \\nendpoint, triggering the Diagnosis Module to \\nanalyze \\nrecent \\ncommits. \\nThis \\nintegration \\nenables a seamless flow of real-time telemetry, \\nlogs, and error tracking data into AI-driven \\nhealing \\nmodels, \\nimproving \\nfault \\ndiagnosis \\nprecision. By combining code analysis with \\ntelemetry, \\nthe \\nsystem \\ncan \\npinpoint \\nroot \\ncauses—like a memory leak tied to a recent \\ndeployment—with 30% faster bug detection \\ncompared to log-only approaches. Additionally, \\nfeedback \\nfrom \\nobservability platforms can \\nfine-tune \\nthe \\nhealing \\nprocess, \\nenabling \\nadaptation to evolving operational conditions \\nand \\nreducing \\ndowntime \\nin \\ndynamic \\nenvironments. \\n8.2 More Robust Multi-Modal Models (Code + \\nLogs + Telemetry) \\nHow can the system better understand failures? \\nMulti-modal models offer a solution by analyzing \\ndata from multiple sources—code, logs, and \\ntelemetry—to provide a holistic view of system \\nbehavior. Traditional approaches often rely on a \\nsingle data stream, missing critical context. A \\nmulti-modal transformer could fuse log data \\n(e.g., error frequency), telemetry (e.g., memory \\nusage), and code embeddings (via CodeBERT) \\nto predict a memory leak’s root cause with 15% \\nhigher accuracy than the prototype’s 40–50% \\nsuccess rate for semantic bugs (Section 5.4). \\nThis addresses context sensitivity (Section 7.3) \\nby enriching the Diagnosis Module (Section 4.2) \\nwith diverse data, enabling it to correlate a spike \\nin failed requests with a specific code change. \\nSuch \\nmodels \\ncan \\ninterpret \\ncomplex \\ninteractions—like \\ncode \\ndependencies \\nand \\nresource \\nusage \\npatterns—generating \\ncontextually \\nappropriate \\nfixes. \\nContinuous \\nlearning from multi-modal data also allows the \\nsystem to adapt to new failure patterns, reducing \\nfalse positives by 15% and ensuring healing \\nactions align with actual system needs across \\ndiverse environments. The effectiveness of \\nmulti-modal \\ntransformers \\nfor \\nsoftware \\nmaintenance \\nand \\ndiagnostics \\nhas \\nbeen \\ndemonstrated in recent studies that show their \\nsuperior ability to learn complex correlations \\nacross diverse inputs [25]. \\n8.3 Reinforcement Learning for Adaptive \\nHealing \\nThe \\nprototype \\nstruggled \\nwith \\nrecurring \\nbugs—reinforcement learning (RL) can address \\n13'),\n",
       " Document(metadata={'producer': 'Skia/PDF m137 Google Docs Renderer', 'creator': '', 'creationdate': '', 'source': '..\\\\data\\\\pdf\\\\Self-Healing_Software_Systems_Lessons_from_Nature_[1].pdf', 'file_path': '..\\\\data\\\\pdf\\\\Self-Healing_Software_Systems_Lessons_from_Nature_[1].pdf', 'total_pages': 16, 'format': 'PDF 1.4', 'title': 'Self-Healing Software', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 13}, page_content='14\\u200b\\nMohammad Baqar ,  Rajat Khanda , Saba Naqvi \\nthis. \\nRL \\nenables \\nself-healing systems to \\ndynamically adapt by learning from continuous \\nfeedback, unlike static ML models. An RL agent \\ncould be trained with a reward function based on \\nrecovery time, learning to prioritize test rewrites \\nover code patches for flaky UI tests, building on \\nthe prototype’s 80% test repair success (Section \\n5.4). For example, if a bug type repeatedly \\noccurs in a specific module, the agent adjusts its \\nstrategy—e.g., favoring configuration fixes over \\ncode changes—targeting a 25% improvement in \\nrecovery time for recurring issues. This iterative \\nlearning optimizes healing actions, tailoring them \\nto the system’s unique patterns and minimizing \\nmanual \\nintervention. \\nRL \\nalso \\nfacilitates \\nautonomous decision-making by evaluating and \\nprioritizing healing strategies based on their \\nlikelihood of success, addressing challenges like \\nfalse positives (Section 7.1) and enhancing \\nefficiency in dynamic environments. \\n8.4 Trust and Explainability Frameworks \\nWill developers trust AI without transparency? \\nAs AI-driven self-healing systems integrate into \\ncritical applications, trust and explainability are \\nessential \\nfor \\nadoption. \\nDevelopers \\nneed \\nconfidence in automated fixes, especially in \\nproduction environments. Using explainable AI \\n(XAI) techniques like SHAP, the system could \\nhighlight that a patch was triggered by a log \\nentry showing 10 failed requests, increasing \\ntrust in the Healing Agent’s decisions (Section \\n4.3). This transparency addresses accountability \\nconcerns \\n(Section \\n7.4), \\nas \\nseen in the \\nprototype’s \\nsemi-autonomous \\nmode \\nwhere \\n60–65% of patches were accepted with minimal \\nedits (Section 5.4). Explainability also aids \\ndebugging \\nby \\nidentifying \\nsuboptimal \\ndecisions—e.g., \\na \\npatch \\nignoring \\na \\ndependency—aiming \\nfor \\n90% \\ndeveloper \\nsatisfaction \\nin \\nunderstanding \\nAI \\nactions, \\nmeasured \\nvia \\nsurveys. \\nEmbedding \\nthese \\nframeworks ensures AI-driven fixes align with \\nbusiness objectives, fostering confidence in \\nmission-critical applications like healthcare and \\nfinance. \\n9. Conclusion \\nAI-driven \\nself-healing \\nsystems \\noffer \\na \\ntransformative vision for software maintenance, \\nautomating \\nthe \\ndetection, \\ndiagnosis, \\nand \\nresolution of issues in real-time. By leveraging \\nadvanced techniques like machine learning, \\ncode analysis, and predictive modeling, these \\nsystems—such as the framework proposed in \\nSection 4—can identify anomalies, bugs, and \\nperformance bottlenecks, achieving recovery \\ntimes up to 55–70% faster than manual fixes, as \\ndemonstrated in the prototype (Section 5.4). \\nThis automation reduces the need for human \\nintervention, freeing developers to focus on \\nstrategic innovation rather than repetitive error \\nfixing. The biological analogy introduced in \\nSection 2 provides an intuitive lens: just as the \\nhuman body uses neural signals to guide \\nimmune responses and repair damaged cells, \\nself-healing software relies on AI to monitor logs, \\ntelemetry, and error reports, directing the healing \\nprocess through modules like Signal Collection \\nand Healing Agent (Section 4). \\nThis analogy’s strength lies in its clarity, making \\nthe concept accessible to both technical and \\nnon-technical stakeholders. Like the body’s \\nability to adapt and regenerate post-injury, \\nsoftware systems can self-correct and recover \\nfrom failures, as seen in the prototype’s 85–90% \\nsuccess rate for syntactic bugs (Section 5.4). \\nContinuous learning, enabled by feedback loops \\n(Section \\n4.5), \\nfosters \\nresilience, \\nallowing \\nsystems to evolve with changing conditions. \\nLooking \\nahead, \\nself-reliant software could \\nmanage \\nits \\nentire \\nlifecycle \\nautonomously, \\nminimizing downtime and boosting efficiency. As \\nAI models advance—addressing challenges like \\nsemantic understanding and scalability (Section \\n7)—the vision of fully autonomous, adaptable \\nsoftware \\nsystems \\nbecomes \\nincreasingly \\nachievable, \\nrevolutionizing \\nsoftware \\ndevelopment and support for a more reliable \\ndigital future.'),\n",
       " Document(metadata={'producer': 'Skia/PDF m137 Google Docs Renderer', 'creator': '', 'creationdate': '', 'source': '..\\\\data\\\\pdf\\\\Self-Healing_Software_Systems_Lessons_from_Nature_[1].pdf', 'file_path': '..\\\\data\\\\pdf\\\\Self-Healing_Software_Systems_Lessons_from_Nature_[1].pdf', 'total_pages': 16, 'format': 'PDF 1.4', 'title': 'Self-Healing Software', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 14}, page_content=\"Self-Healing Software Systems: Lessons from Nature, Powered by AI \\nReferences \\n[1] Brown et al., “Language Models are Few-Shot Learners,” OpenAI, 2020. \\n[2] Lewis et al., “Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks,” NeurIPS, 2020. \\n[3] Sigelman et al., “Instrumentation and Observability in Distributed Systems,” Google SRE Book, 2016. \\n[4] Monperrus, M., “Automatic Software Repair: A Bibliography,” ACM Computing Surveys, 2018. \\n[5] Martinez and Monperrus, “Repairnator: An Open Source Program Repair Toolchain,” ICSE Demo Track, 2018. \\n[6] GitHub, “About Git Version Control,” docs.github.com, 2024. \\n[7] Netflix, “The Chaos Monkey Guide,” Netflix Tech Blog, 2016. \\n[8] Burns, B., et al., “Kubernetes: Up and Running,” O'Reilly, 2019. \\n[9] Weimer et al., “Automatically Finding Patches Using Genetic Programming,” ICSE, 2009. \\n[10] Sidiroglou-Douskos et al., “Automatic Runtime Error Repair with CodePhage,” PLDI, 2015. \\n[11] Chen et al., “Evaluating Large Language Models Trained on Code,” arXiv preprint arXiv:2107.03374, 2021. \\n[12] Luo et al., “An Empirical Study of Flaky Tests,” FSE, 2014. \\n[13] Godefroid et al., “Grammar-based Whitebox Fuzzing,” PLDI, 2008. \\n[14] Wang et al., “CodeT5: Identifier-aware Unified Pre-trained Encoder-Decoder Models for Code Understanding \\nand Generation,” EMNLP, 2021. \\n[15] DeepMind, “AlphaCode: Competitive Programming with AI,” Science, 2022. \\n[16] Ramanan et al., “Hallucination in AI-Generated Code: Causes, Risks, and Mitigations,” arXiv preprint \\narXiv:2302.11195, 2023. \\n[17] Papadakis, M., Traon, Y. L., & Harman, M. (2019). Mutation Testing Advances: An Analysis and Survey. \\nAdvances in Computers, 112, 275–378. https://doi.org/10.1016/bs.adcom.2018.03.015 \\n[18] Chen, T., Mao, Y., & Xiao, Y. (2021). A Survey on Continuous Integration and Continuous Delivery: Practices, \\nChallenges, and Research Directions. ACM Computing Surveys (CSUR), 54(6), 1–36. \\nhttps://doi.org/10.1145/3451213 \\n[19] Pradel, M., & Sen, K. (2018). DeepBugs: A Learning Approach to Name-based Bug Detection. Proceedings of \\nthe ACM on Programming Languages, 2(OOPSLA), 1–25. https://doi.org/10.1145/3276517 \\n[20] Chen, Q., Martinez, M., & Monperrus, M. (2019). A Literature Study of Automated Program Repair. ACM \\nComputing Surveys (CSUR), 51(1), 1–36. https://doi.org/10.1145/3054926 \\n[21] Tufano, M., Watson, C., Bavota, G., Poshyvanyk, D., & White, M. (2019). An Empirical Study on Learning \\nBug-Fixing Patches in the Wild via Neural Machine Translation. ACM Transactions on Software Engineering and \\nMethodology (TOSEM), 28(4), 1–29. https://doi.org/10.1145/3340515 \\n[22] Chen, M., Tworek, J., Jun, H., Yuan, Q., de Oliveira Pinto, H. P., Kaplan, J., Edwards, H., Burda, Y., Joseph, N., \\nBrockman, G., Ray, A., Puri, R., Krueger, G., Petrov, M., Khlaaf, H., Sastry, G., Mishkin, P., Chan, B., Gray, S., ... \\n15\"),\n",
       " Document(metadata={'producer': 'Skia/PDF m137 Google Docs Renderer', 'creator': '', 'creationdate': '', 'source': '..\\\\data\\\\pdf\\\\Self-Healing_Software_Systems_Lessons_from_Nature_[1].pdf', 'file_path': '..\\\\data\\\\pdf\\\\Self-Healing_Software_Systems_Lessons_from_Nature_[1].pdf', 'total_pages': 16, 'format': 'PDF 1.4', 'title': 'Self-Healing Software', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 15}, page_content='16\\u200b\\nMohammad Baqar ,  Rajat Khanda , Saba Naqvi \\nAmodei, D. (2021). Evaluating Large Language Models Trained on Code. arXiv preprint arXiv:2107.03374. \\nhttps://arxiv.org/abs/2107.03374 \\n[23] Xia, X., Fu, Q., Lo, D., & Xu, B. (2017). Automated Source Code Summarization: A Systematic Literature \\nReview. Information and Software Technology, 87, 57–77. https://doi.org/10.1016/j.infsof.2017.02.002 \\n[24] Leslie, D. (2019). Understanding Artificial Intelligence Ethics and Safety: A Guide for the Responsible \\nDesign and Implementation of AI Systems in the Public Sector. The Alan Turing Institute. \\nhttps://doi.org/10.5281/zenodo.3240529 \\n[25] Ahmed, F., Li, Y., Duan, Y., & Zhang, Y. (2023). Multi-Modal Transformer for Software Fault Localization \\nUsing Logs, Code, and Telemetry. Proceedings of the 45th International Conference on Software Engineering \\n(ICSE). https://doi.org/10.1109/ICSE58661.2023.00083')]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader,PyMuPDFLoader\n",
    "\n",
    "dir_loader=DirectoryLoader(\n",
    "    \"../data/pdf\",\n",
    "    glob=\"**/*.pdf\",\n",
    "    loader_cls=PyMuPDFLoader,\n",
    "   # loader_kwargs={'encoding':'utf-8'},\n",
    "    show_progress=False\n",
    "    \n",
    ")\n",
    "\n",
    "pdf_doc=dir_loader.load()\n",
    "pdf_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79615cc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain_core.documents.base.Document"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(pdf_doc[0])\n",
    "# these are all data strcuture format \n",
    "# now the chunking takes place after converting it to document data struture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40abaca2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TRAG (3.13.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
